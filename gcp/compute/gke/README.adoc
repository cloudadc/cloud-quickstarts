= GKE
:toc: manual

== GKE Cluster Quick Start

=== Deploy GKE Cluster

[source, bash]
.*1. set the zone to run cluster and the cluster name*
----
export my_zone=us-central1-a
export my_cluster=standard-cluster-1
----

[source, bash]
.*2. Create cluster*
----
gcloud container clusters create $my_cluster --num-nodes=3 --zone=$my_zone --enable-ip-alias
----

* `--enable-ip-alias` -  his will require at least two secondary ranges in the subnetwork, one for the pod IPs and another to reserve space for the services range.

*3. Verify Install*

* Node and Nodepool

[source, bash]
----
$ kubectl get nodes -o wide
NAME                                                STATUS   ROLES    AGE   VERSION             INTERNAL-IP   EXTERNAL-IP      OS-IMAGE                             KERNEL-VERSION   CONTAINER-RUNTIME
gke-standard-cluster-1-default-pool-94f51f94-6znp   Ready    <none>   12m   v1.24.10-gke.2300   10.128.0.3    34.172.140.126   Container-Optimized OS from Google   5.10.162+        containerd://1.6.9
gke-standard-cluster-1-default-pool-94f51f94-gxsc   Ready    <none>   12m   v1.24.10-gke.2300   10.128.0.5    34.132.208.226   Container-Optimized OS from Google   5.10.162+        containerd://1.6.9
gke-standard-cluster-1-default-pool-94f51f94-ltjz   Ready    <none>   12m   v1.24.10-gke.2300   10.128.0.4    34.30.102.248    Container-Optimized OS from Google   5.10.162+        containerd://1.6.9
----

* Defualt Pod(Metrics exporter, LB Kube-proxy, DNS kube-dns, CNI)

[source, bash]
----
$ kubectl get pods -A -o wide
NAMESPACE     NAME                                                           READY   STATUS    RESTARTS   AGE   IP           NODE                                                NOMINATED NODE   READINESS GATES
kube-system   event-exporter-gke-857959888b-n8zdr                            2/2     Running   0          11m   10.8.0.2     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   fluentbit-gke-gqtz8                                            2/2     Running   0          10m   10.128.0.4   gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   fluentbit-gke-ngt9s                                            2/2     Running   0          10m   10.128.0.5   gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   fluentbit-gke-nvd8c                                            2/2     Running   0          10m   10.128.0.3   gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   gke-metrics-agent-rx4hv                                        1/1     Running   0          10m   10.128.0.3   gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   gke-metrics-agent-vgmvq                                        1/1     Running   0          10m   10.128.0.5   gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   gke-metrics-agent-vlwtr                                        1/1     Running   0          10m   10.128.0.4   gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   konnectivity-agent-7888984c76-2p7nw                            1/1     Running   0          11m   10.8.0.6     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   konnectivity-agent-7888984c76-95svx                            1/1     Running   0          10m   10.8.2.4     gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   konnectivity-agent-7888984c76-r2zcj                            1/1     Running   0          10m   10.8.1.3     gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   konnectivity-agent-autoscaler-7d9fbfd578-wc2lv                 1/1     Running   0          11m   10.8.0.5     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   kube-dns-7d5998784c-lbnmj                                      4/4     Running   0          11m   10.8.1.2     gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   kube-dns-7d5998784c-sk4zb                                      4/4     Running   0          10m   10.8.2.3     gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   kube-dns-autoscaler-9f89698b6-zxfbk                            1/1     Running   0          11m   10.8.0.3     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-6znp   1/1     Running   0          10m   10.128.0.3   gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-gxsc   1/1     Running   0          10m   10.128.0.5   gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-ltjz   1/1     Running   0          10m   10.128.0.4   gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   l7-default-backend-6dc845c45d-j792m                            1/1     Running   0          11m   10.8.2.2     gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   metrics-server-v0.5.2-6bf845b67f-rmp5w                         2/2     Running   0          10m   10.8.0.7     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   pdcsi-node-64slt                                               2/2     Running   0          10m   10.128.0.5   gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   pdcsi-node-dclhr                                               2/2     Running   0          10m   10.128.0.4   gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   pdcsi-node-j2jfz                                               2/2     Running   0          10m   10.128.0.3   gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
----

* The Installed K8S has 3 nodes, each with ip address `10.128.0.3`, `10.128.0.4` and `10.128.0.5`
* The Pod CIRD is `10.8.0.0/14`
* The Service CIRD is `10.12.0.0/20`
* The apiserver, controller pod are not run on NODE.

* Verify VPC subnet

[source, json]
----
{
  "creationTimestamp": "2023-04-22T15:49:29.660-07:00",
  "fingerprint": "Oyz4MMoy5mQ=",
  "gatewayAddress": "10.128.0.1",
  "id": "4585684495711722134",
  "ipCidrRange": "10.128.0.0/20",
  "kind": "compute#subnetwork",
  "name": "default",
  "network": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/global/networks/default",
  "privateIpGoogleAccess": true,
  "privateIpv6GoogleAccess": "DISABLE_GOOGLE_ACCESS",
  "purpose": "PRIVATE",
  "region": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1",
  "secondaryIpRanges": [
    {
      "ipCidrRange": "10.12.0.0/20",
      "rangeName": "gke-standard-cluster-1-services-4452472e"
    },
    {
      "ipCidrRange": "10.8.0.0/14",
      "rangeName": "gke-standard-cluster-1-pods-4452472e"
    }
  ],
  "selfLink": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1/subnetworks/default",
  "stackType": "IPV4_ONLY"
}
----

NOTE: The `default` vpc network has subnet with ipCidrRange `10.128.0.0/20`, the subnet also has 2 secondaryIpRanges `10.8.0.0/14` and `10.12.0.0/20`.

=== Modify GKE Cluster

[source, bash]
.*1. Change the cluster node number to 4*
----
gcloud container clusters resize $my_cluster --zone=$my_zone --num-nodes=4
----

[source, bash]
.*2. Veiw the nodes*
----
$ kubectl get nodes -o wide
NAME                                                STATUS   ROLES    AGE   VERSION             INTERNAL-IP   EXTERNAL-IP      OS-IMAGE                             KERNEL-VERSION   CONTAINER-RUNTIME
gke-standard-cluster-1-default-pool-94f51f94-1571   Ready    <none>   16m   v1.24.10-gke.2300   10.128.0.6    34.28.234.55     Container-Optimized OS from Google   5.10.162+        containerd://1.6.9
gke-standard-cluster-1-default-pool-94f51f94-6znp   Ready    <none>   39m   v1.24.10-gke.2300   10.128.0.3    34.172.140.126   Container-Optimized OS from Google   5.10.162+        containerd://1.6.9
gke-standard-cluster-1-default-pool-94f51f94-gxsc   Ready    <none>   39m   v1.24.10-gke.2300   10.128.0.5    34.132.208.226   Container-Optimized OS from Google   5.10.162+        containerd://1.6.9
gke-standard-cluster-1-default-pool-94f51f94-ltjz   Ready    <none>   39m   v1.24.10-gke.2300   10.128.0.4    34.30.102.248    Container-Optimized OS from Google   5.10.162+        containerd://1.6.9
----

[source, bash]
.*3. View the pods*
----
$ kubectl get pods -A -o wide
NAMESPACE     NAME                                                           READY   STATUS    RESTARTS   AGE   IP           NODE                                                NOMINATED NODE   READINESS GATES
kube-system   event-exporter-gke-857959888b-n8zdr                            2/2     Running   0          41m   10.8.0.2     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   fluentbit-gke-gqtz8                                            2/2     Running   0          40m   10.128.0.4   gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   fluentbit-gke-hnl6j                                            2/2     Running   0          17m   10.128.0.6   gke-standard-cluster-1-default-pool-94f51f94-1571   <none>           <none>
kube-system   fluentbit-gke-ngt9s                                            2/2     Running   0          40m   10.128.0.5   gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   fluentbit-gke-nvd8c                                            2/2     Running   0          40m   10.128.0.3   gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   gke-metrics-agent-dnrr9                                        1/1     Running   0          17m   10.128.0.6   gke-standard-cluster-1-default-pool-94f51f94-1571   <none>           <none>
kube-system   gke-metrics-agent-rx4hv                                        1/1     Running   0          40m   10.128.0.3   gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   gke-metrics-agent-vgmvq                                        1/1     Running   0          40m   10.128.0.5   gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   gke-metrics-agent-vlwtr                                        1/1     Running   0          40m   10.128.0.4   gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   konnectivity-agent-7888984c76-2p7nw                            1/1     Running   0          41m   10.8.0.6     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   konnectivity-agent-7888984c76-95svx                            1/1     Running   0          40m   10.8.2.4     gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   konnectivity-agent-7888984c76-jrbtz                            1/1     Running   0          17m   10.8.3.2     gke-standard-cluster-1-default-pool-94f51f94-1571   <none>           <none>
kube-system   konnectivity-agent-7888984c76-r2zcj                            1/1     Running   0          40m   10.8.1.3     gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   konnectivity-agent-autoscaler-7d9fbfd578-wc2lv                 1/1     Running   0          41m   10.8.0.5     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   kube-dns-7d5998784c-lbnmj                                      4/4     Running   0          41m   10.8.1.2     gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   kube-dns-7d5998784c-sk4zb                                      4/4     Running   0          40m   10.8.2.3     gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   kube-dns-autoscaler-9f89698b6-zxfbk                            1/1     Running   0          41m   10.8.0.3     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-1571   1/1     Running   0          17m   10.128.0.6   gke-standard-cluster-1-default-pool-94f51f94-1571   <none>           <none>
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-6znp   1/1     Running   0          39m   10.128.0.3   gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-gxsc   1/1     Running   0          40m   10.128.0.5   gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-ltjz   1/1     Running   0          39m   10.128.0.4   gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   l7-default-backend-6dc845c45d-j792m                            1/1     Running   0          41m   10.8.2.2     gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   metrics-server-v0.5.2-6bf845b67f-rmp5w                         2/2     Running   0          39m   10.8.0.7     gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
kube-system   pdcsi-node-64slt                                               2/2     Running   0          40m   10.128.0.5   gke-standard-cluster-1-default-pool-94f51f94-gxsc   <none>           <none>
kube-system   pdcsi-node-9sqwb                                               2/2     Running   0          17m   10.128.0.6   gke-standard-cluster-1-default-pool-94f51f94-1571   <none>           <none>
kube-system   pdcsi-node-dclhr                                               2/2     Running   0          40m   10.128.0.4   gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
kube-system   pdcsi-node-j2jfz                                               2/2     Running   0          40m   10.128.0.3   gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
----

=== Connect to a GKE cluster

[source, bash]
.*1. Fetching cluster endpoint and auth data*
----
gcloud container clusters get-credentials $my_cluster --zone $my_zone
----

[source, bash]
.*2. View the kube config file*
----
cat ~/.kube/config
----

=== Use kubectl to inspect a GKE cluster

[source, bash]
.*1. kubeconfig file view*
----
kubectl config view
----

[source, bash]
.*2. CLuster view*
----
$ kubectl cluster-info
Kubernetes control plane is running at https://34.123.72.123
GLBCDefaultBackend is running at https://34.123.72.123/api/v1/namespaces/kube-system/services/default-http-backend:http/proxy
KubeDNS is running at https://34.123.72.123/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
Metrics-server is running at https://34.123.72.123/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy
----

[source, bash]
.*3. Switch K8S Context*
----
kubectl config current-context
kubectl config get-contexts
kubectl config use-context gke_${GOOGLE_CLOUD_PROJECT}_us-central1-a_standard-cluster-1
----

[source, bash]
.*4. Resource Usage view*
----
$ kubectl top nodes
NAME                                                CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
gke-standard-cluster-1-default-pool-94f51f94-1571   91m          9%     650Mi           23%
gke-standard-cluster-1-default-pool-94f51f94-6znp   129m         13%    756Mi           26%
gke-standard-cluster-1-default-pool-94f51f94-gxsc   104m         11%    711Mi           25%
gke-standard-cluster-1-default-pool-94f51f94-ltjz   97m          10%    705Mi           25%

$ kubectl top pods -A
NAMESPACE     NAME                                                           CPU(cores)   MEMORY(bytes)
kube-system   event-exporter-gke-857959888b-n8zdr                            1m           21Mi
kube-system   fluentbit-gke-gqtz8                                            7m           22Mi
kube-system   fluentbit-gke-hnl6j                                            7m           21Mi
kube-system   fluentbit-gke-ngt9s                                            9m           23Mi
kube-system   fluentbit-gke-nvd8c                                            7m           21Mi
kube-system   gke-metrics-agent-dnrr9                                        3m           26Mi
kube-system   gke-metrics-agent-rx4hv                                        3m           27Mi
kube-system   gke-metrics-agent-vgmvq                                        3m           26Mi
kube-system   gke-metrics-agent-vlwtr                                        3m           28Mi
kube-system   konnectivity-agent-7888984c76-2p7nw                            1m           6Mi
kube-system   konnectivity-agent-7888984c76-95svx                            1m           6Mi
kube-system   konnectivity-agent-7888984c76-jrbtz                            1m           7Mi
kube-system   konnectivity-agent-7888984c76-r2zcj                            1m           6Mi
kube-system   konnectivity-agent-autoscaler-7d9fbfd578-wc2lv                 1m           3Mi
kube-system   kube-dns-7d5998784c-lbnmj                                      3m           30Mi
kube-system   kube-dns-7d5998784c-sk4zb                                      3m           28Mi
kube-system   kube-dns-autoscaler-9f89698b6-zxfbk                            1m           11Mi
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-1571   1m           25Mi
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-6znp   1m           23Mi
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-gxsc   1m           25Mi
kube-system   kube-proxy-gke-standard-cluster-1-default-pool-94f51f94-ltjz   1m           23Mi
kube-system   l7-default-backend-6dc845c45d-j792m                            1m           2Mi
kube-system   metrics-server-v0.5.2-6bf845b67f-rmp5w                         12m          29Mi
kube-system   pdcsi-node-64slt                                               33m          9Mi
kube-system   pdcsi-node-9sqwb                                               39m          10Mi
kube-system   pdcsi-node-dclhr                                               34m          10Mi
kube-system   pdcsi-node-j2jfz                                               34m          9Mi
----

=== Deploy Pods to GKE cluster

[source, bash]
.*1. Create a workloads*
----
kubectl apply -f nginx.yaml
----

NOTE: the above commands will create 3 K8S Objects, `Namespace`, `Deployment` and `HorizontalPodAutoscaler`, which the `Deployment` will create 3 nginx pods and `HorizontalPodAutoscaler` will make nginx nginx horizontal scale to max 5 nginx pods, the scle crertia via POD CPU Usage, if POD CPU usage exceed 80%, the horizontal scale will start.

* link:nginx.yaml[nginx.yaml]

[source, bash]
.*2. Review the deployed workload*
----
$ kubectl get deploy -n nginx
NAME      READY   UP-TO-DATE   AVAILABLE   AGE
nginx-1   3/3     3            3           2m12s

$ kubectl get rs -n nginx
NAME                 DESIRED   CURRENT   READY   AGE
nginx-1-5775447459   3         3         3       8m

$ kubectl get hpa -n nginx
NAME               REFERENCE            TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
nginx-1-hpa-ekh8   Deployment/nginx-1   <unknown>/80%   1         5         3          2m31s

$ kubectl get pods -n nginx -o wide
NAME                       READY   STATUS    RESTARTS   AGE   IP         NODE                                                NOMINATED NODE   READINESS GATES
nginx-1-5775447459-jcqmw   1/1     Running   0          85s   10.8.3.3   gke-standard-cluster-1-default-pool-94f51f94-1571   <none>           <none>
nginx-1-5775447459-kc7gp   1/1     Running   0          85s   10.8.1.4   gke-standard-cluster-1-default-pool-94f51f94-ltjz   <none>           <none>
nginx-1-5775447459-n8zc8   1/1     Running   0          85s   10.8.0.8   gke-standard-cluster-1-default-pool-94f51f94-6znp   <none>           <none>
----

[source, bash]
.*3. Create test.html with the following content*
----
<html> <header><title>This is title</title></header>
<body> Hello world </body>
</html>
----

[source, bash]
.*4. Copy the test.html to POD*
----
for i in $(kubectl get pods -n nginx --no-headers | awk '{print $1}') ; do kubectl cp ~/test.html $i:/usr/share/nginx/html/test.html -n nginx ; done
----

[source, bash]
.*5. Create Service*
----
kubectl expose deployment nginx-1 -n nginx --port 80 --type LoadBalancer
kubectl expose pod nginx-1-5775447459-jcqmw -n nginx --port 80 --type LoadBalancer
----

[source, bash]
.*6. View the Service*
----
$ kubectl get svc -n nginx
NAME                       TYPE           CLUSTER-IP    EXTERNAL-IP     PORT(S)        AGE
nginx-1                    LoadBalancer   10.12.0.79    34.134.216.0    80:32709/TCP   2m8s
nginx-1-5775447459-jcqmw   LoadBalancer   10.12.7.131   34.122.186.90   80:30055/TCP   46s
----

[source, bash]
.*7. Test Service*
----
$ curl 34.134.216.0/test.html -I
HTTP/1.1 200 OK
Server: nginx/1.23.4
Date: Sun, 23 Apr 2023 04:26:33 GMT
Content-Type: text/html
Content-Length: 88
Last-Modified: Sun, 23 Apr 2023 04:21:45 GMT
Connection: keep-alive
ETag: "6444b259-58"
Accept-Ranges: bytes

$ curl 34.122.186.90/test.html -I
HTTP/1.1 200 OK
Server: nginx/1.23.4
Date: Sun, 23 Apr 2023 04:26:56 GMT
Content-Type: text/html
Content-Length: 88
Last-Modified: Sun, 23 Apr 2023 04:21:45 GMT
Connection: keep-alive
ETag: "6444b259-58"
Accept-Ranges: bytes
----

[source, bash]
.*8. View Pod Triffic*
----
$ kubectl top pods -n nginx
NAME                       CPU(cores)   MEMORY(bytes)
nginx-1-5775447459-jcqmw   0m           2Mi
nginx-1-5775447459-kc7gp   0m           2Mi
nginx-1-5775447459-n8zc8   1m           2Mi
----

=== Service Deep Dive

[source, bash]
.*1. The Address view*
----
$ gcloud compute forwarding-rules list --format=json
[
  {
    "IPAddress": "34.134.216.0",
    "IPProtocol": "TCP",
    "creationTimestamp": "2023-04-22T21:23:53.084-07:00",
    "description": "{\"kubernetes.io/service-name\":\"nginx/nginx-1\"}",
    "fingerprint": "qdJJe3qIfnE=",
    "id": "5094408519925959734",
    "kind": "compute#forwardingRule",
    "labelFingerprint": "42WmSpB8rSM=",
    "loadBalancingScheme": "EXTERNAL",
    "name": "a0d8377cb4dd448fcb49de19f7067ed5",
    "networkTier": "PREMIUM",
    "portRange": "80-80",
    "region": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1",
    "selfLink": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1/forwardingRules/a0d8377cb4dd448fcb49de19f7067ed5",
    "target": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1/targetPools/a0d8377cb4dd448fcb49de19f7067ed5"
  }
]
----

[source, bash]
.*2. The target-pool view*
----
$ gcloud compute target-pools list --format=json
[
  {
    "creationTimestamp": "2023-04-22T21:23:49.396-07:00",
    "description": "{\"kubernetes.io/service-name\":\"nginx/nginx-1\"}",
    "healthChecks": [
      "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/global/httpHealthChecks/k8s-e634c17ad66069de-node"
    ],
    "id": "4677497706655583290",
    "instances": [
      "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/zones/us-central1-a/instances/gke-standard-cluster-1-default-pool-94f51f94-6znp",
      "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/zones/us-central1-a/instances/gke-standard-cluster-1-default-pool-94f51f94-1571"
    ],
    "kind": "compute#targetPool",
    "name": "a0d8377cb4dd448fcb49de19f7067ed5",
    "region": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1",
    "selfLink": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1/targetPools/a0d8377cb4dd448fcb49de19f7067ed5",
    "sessionAffinity": "NONE"
  }
]
----

[source, bash]
.*3. The forward-rules view*
----
$ gcloud compute forwarding-rules list --format=json
[
  {
    "IPAddress": "34.134.216.0",
    "IPProtocol": "TCP",
    "creationTimestamp": "2023-04-22T21:23:53.084-07:00",
    "description": "{\"kubernetes.io/service-name\":\"nginx/nginx-1\"}",
    "fingerprint": "qdJJe3qIfnE=",
    "id": "5094408519925959734",
    "kind": "compute#forwardingRule",
    "labelFingerprint": "42WmSpB8rSM=",
    "loadBalancingScheme": "EXTERNAL",
    "name": "a0d8377cb4dd448fcb49de19f7067ed5",
    "networkTier": "PREMIUM",
    "portRange": "80-80",
    "region": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1",
    "selfLink": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1/forwardingRules/a0d8377cb4dd448fcb49de19f7067ed5",
    "target": "https://www.googleapis.com/compute/v1/projects/playground-s-11-b1e7037d/regions/us-central1/targetPools/a0d8377cb4dd448fcb49de19f7067ed5"
  }
]
----

=== Delete GKE Cluster

[source, bash]
----
gcloud container clusters delete $my_cluster --zone=$my_zone
----

== GKE Cluster Deployment

=== Create a deployment

[source, bash]
.*1. Create Deployment*
----
kubectl apply -f nginx/deploy.yaml
----

* link:nginx/deploy.yaml[nginx/deploy.yaml]

[source, bash]
.*2. View Deployment*
----
$ kubectl get deployment -n nginx
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
nginx   3/3     3            3           2m26s
----

=== Scale up and down 

[source, bash]
.*1. Scale down*
----
kubectl scale --replicas=1 deployment nginx -n nginx
----

[source, bash]
.*2. Scale up*
----
kubectl scale --replicas=5 deployment nginx -n nginx
----

=== Deployment rollout and rollback 

[source, bash]
.*1. Update the version of nginx in the deployment*
----
kubectl set image deployment nginx -n nginx nginx=nginx:1.24.0 --record
----

[source, bash]
.*2. View the rollout status*
----
$ kubectl rollout status deployment nginx -n nginx
Waiting for deployment "nginx" rollout to finish: 1 out of 3 new replicas have been updated...
Waiting for deployment "nginx" rollout to finish: 1 out of 3 new replicas have been updated...
Waiting for deployment "nginx" rollout to finish: 1 out of 3 new replicas have been updated...
Waiting for deployment "nginx" rollout to finish: 2 out of 3 new replicas have been updated...
Waiting for deployment "nginx" rollout to finish: 2 out of 3 new replicas have been updated...
Waiting for deployment "nginx" rollout to finish: 2 out of 3 new replicas have been updated...
Waiting for deployment "nginx" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "nginx" rollout to finish: 1 old replicas are pending termination...
deployment "nginx" successfully rolled out
----

[source, bash]
.*3. View the rollout history*
----
$ kubectl rollout history deployment nginx -n nginx
deployment.apps/nginx
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image deployment nginx nginx=nginx:1.24.0 --namespace=nginx --record=true
3         kubectl set image deployment nginx nginx=nginx:1.23.3 --namespace=nginx --record=true
4         kubectl set image deployment nginx nginx=nginx:1.23.2 --namespace=nginx --record=true
----

[source, bash]
.*4. rollback*
----
$ kubectl rollout undo deployments nginx -n nginx
----

=== Horizontal Autoscaler

[source, bash]
.*1. Create*
----
kubectl apply -f nginx/hpa.yaml
----

* link:nginx/hpa.yaml[nginx/hpa.yaml]

[source, bash]
.*2. Verify*
----
$ kubectl get hpa -n nginx
NAME               REFERENCE          TARGETS         MINPODS   MAXPODS   REPLICAS   AGE
nginx-1-hpa-ekh8   Deployment/nginx   <unknown>/80%   1         5         5          105s
----

=== Define the service type

[source, bash]
.*1. Create Service*
----
kubectl apply -f nginx/svc.yaml
----

* link:nginx/svc.yaml[nginx/svc.yaml]

[source, bash]
.*2. View Service*
----
$ kubectl get svc -n nginx
NAME    TYPE           CLUSTER-IP    EXTERNAL-IP   PORT(S)           AGE
nginx   LoadBalancer   10.12.9.178   34.30.91.93   60000:31198/TCP   2m47s
----

[source, bash]
.*3. Access Service*
----
$ curl 34.30.91.93:60000 -I
HTTP/1.1 200 OK
Server: nginx/1.23.3
Date: Sun, 23 Apr 2023 07:38:04 GMT
Content-Type: text/html
Content-Length: 615
Last-Modified: Tue, 13 Dec 2022 15:53:53 GMT
Connection: keep-alive
ETag: "6398a011-267"
Accept-Ranges: bytes
----

=== Canary deployment

[source, bash]
.*1. Create the canary deployment*
----
kubectl apply -f nginx/canary.yaml
----

* link:nginx/canary.yaml[nginx/canary.yaml]

[source, bash]
.*2. View Deployment*
----
$ kubectl get deployment -n nginx
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
nginx          3/3     3            3           34m
nginx-canary   1/1     1            1           5m1s
----

[source, bash]
.*3. Access service from LB(25% traffic goes into new version)*
----
$ for i in {1..10} ; do curl -s 34.30.91.93:60000 -I | grep Server ; done
Server: nginx/1.24.0
Server: nginx/1.23.4
Server: nginx/1.23.4
Server: nginx/1.23.4
Server: nginx/1.24.0
Server: nginx/1.23.4
Server: nginx/1.23.4
Server: nginx/1.23.4
Server: nginx/1.24.0
Server: nginx/1.23.4
----

[source, bash]
.*4. Scale down all old version*
----
kubectl scale --replicas=0 deployment nginx -n nginx
----

[source, bash]
.*5. Access service from LB, all trffic goes into new version*
----
$ for i in {1..10} ; do curl -s 34.30.91.93:60000 -I | grep Server ; done
Server: nginx/1.24.0
Server: nginx/1.24.0
Server: nginx/1.24.0
Server: nginx/1.24.0
Server: nginx/1.24.0
Server: nginx/1.24.0
Server: nginx/1.24.0
Server: nginx/1.24.0
Server: nginx/1.24.0
Server: nginx/1.24.0
----

=== Session affinity

[source, bash]
----
apiVersion: v1
kind: Service
metadata:
  name: nginx
  namespace: nginx
spec:
  type: LoadBalancer
  sessionAffinity: ClientIP
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 60000
    targetPort: 80
----

== Job & CronJob

=== Define a Job

[source, bash]
.*1. Create a Job*
----
kubectl apply -f job/job.yaml
----

* link:job/job.yaml[job/job.yaml]

[source, bash]
.*2. View the results*
----
$ kubectl logs -f $(kubectl get pods --no-headers | awk '{print $1}')
3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901
----

[source, bash]
.*3. Clean the Job*
----
kubectl delete job example-job
----

=== Define a CronJob

[source, bash]
.*1. Create a CronJob*
----
kubectl apply -f job/cronjob.yaml
----

* link:job/cronjob.yaml[job/cronjob.yaml]

[source, bash]
.*2. View Jobs*
----
$ kubectl get jobs
NAME             COMPLETIONS   DURATION   AGE
hello-28037360   1/1           5s         2m41s
hello-28037361   1/1           4s         101s
hello-28037362   1/1           4s         41s

$ kubectl get pods
NAME                   READY   STATUS      RESTARTS   AGE
hello-28037360-9qh99   0/1     Completed   0          2m49s
hello-28037361-sfj9f   0/1     Completed   0          109s
hello-28037362-lbsz6   0/1     Completed   0          49s
----

[source, bash]
.*3. View Jobs output*
----
$ for i in $(kubectl get pods --no-headers | awk '{print $1}') ; do kubectl logs -f $i ; done
Sun Apr 23 09:22:01 UTC 2023
Hello, World!
Sun Apr 23 09:23:01 UTC 2023
Hello, World!
Sun Apr 23 09:24:01 UTC 2023
Hello, World!
----


[source, bash]
.**
----

----

[source, bash]
.**
----

----

[source, bash]
.**
----

----

[source, bash]
.**
----

----

[source, bash]
.**
----

----

[source, bash]
.**
----

----

[source, bash]
.**
----

----

[source, bash]
.**
----

----

[source, bash]
.**
----

----
